# Planejamento da avaliação

## 1. Contextualização

<p align="justify"> &emsp;&emsp; Nessa etapa do projeto iremos avaliar as análises de tarefas e os storyboards. Uma das etapadas da análise será por testes-piloto. Foi criado um documento separado para o planejamento dos testes-piloto que pode ser acessado <a href="https://interacao-humano-computador.github.io/2020.1-UVaJudge/entrega_4/planejamento_teste_piloto/">aqui</a></p>

## 2. Objetivos da avaliação

<p align="justify"> &emsp;&emsp; Os objetivos serão expostos por meio de um conjunto de perguntas, segue abaixo as perguntas.</p>

### 2.1 Perguntas Análise de tarefas

1. Os erros diagnosticados na análise de tarefas foram também identificados nos testes-piloto?
2. As atividades dos usuários foram devidamente identificadas na avaliação?
3. Os objetivos das personas estão fiéis ao nosso perfil de usuário e aos dados coletados nas entrevitas e avaliações?
4. O erro encontrado na análise de tarefas da Maria lee Oliveira foi relatado durante o teste-piloto?

### 2.2 Perguntas Storyboard

1. Os erros diagnosticados nos storyboards foram também identificados nos testes-piloto?
2. As atividades dos usuários foram devidamente identificadas na avaliação?
3. Os objetivos das personas são refletidos nos storyboards?
4. Os participantes do teste-piloto conseguem se identificar com alguma história contada nos storyboards?
5. As personas executam atividades presentes storyboards?

## 3. Metodologia

<p align="justify"> &emsp;&emsp; A nossa técnica adotada para a coleta dos dados será uma simbiose das técnicas existentes. A primeira delas será o percuso cognitivo, onde o avaliado irá simular que é um usuário, para isso, será usado as personas que foram criadas anteriomente. O segundo meio que vamos utilizar é a análise heurística, na qual, através de uma análise do UVa, iremos verificar se ele está dentro dos parâmetros esperados e estipulados das metas de usabilidades. Essa avaliação que vai ser útil pois é um método eficaz e rápido de encontrar os problemas de usabilidade mais básicos de um sistema. E o último vai ser pelas entrevistas e testes-pilotos feitos por vídeo-chamadas. Neles iremos verificar a qualidade dos protótipos, storyboards, grids e demais protótipos e ferramentas usadas no auxílio às análises criadas.</p>

<p align="justify"> &emsp;&emsp; Os entrevistados selecionados foram seletivamente escolhidos baseado em seu prévio contato com competições e disciplinas de programação. Dessa maneira, nossos dados estarão de acordo com o público alvo do UVa.</p>

## 4. Relato dos resultados

<p align="justify"> &emsp;&emsp; Os relatos vão ser colocados em um documento criado futuramente, nesse documento a ser gerado iremos colocar as respostas para as perguntas definidas na Seção 2. Os dados serão expressos por meios de textos que vão dissertar sobre as qualidades e os defeitos encontrados ao longo da avaliação. Assim, com essa avaliação poderemos definir se seguiremos para o nível 2 da seção de design, avaliação e desenvolvimento do ciclo Mayhew definido no processo de design.</p>

## 5. Versionamento

<p align="justify"> &emsp;&emsp; versionamentos iguais para descrições diferentes ocorrem quando o trabalho é feito em equipe, assim, é separado no versionamento apenas por organização.</p>

|Data|Versão|Descrição|Autor|
|:-:|:-:|:-:|:-:|
|27/09/2020|1.0|Adições nos tópicos 1, 2, 3 e 4|Sérgio Cipriano|
|27/09/2020|1.0|Adições nos tópicos 3 e 4|Washington Bispo|
|10/11/2020|1.1|Correção de erros nos tópicos 2.2 e 4|Sérgio Cipriano|
|10/11/2020|1.1|Adição do tópico 2.1|Washington Bispo|
