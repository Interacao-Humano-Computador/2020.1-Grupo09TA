# Planejamento da avaliação

## 1. Contextualização

<p align="justify"> &emsp;&emsp; Nessa etapa do projeto iremos avaliar as análises de tarefas e os storyboards. Uma das etapadas da análise será por testes-piloto. Foi criado um documento separado para o planejamento dos testes-piloto que pode ser acessado <a href="https://interacao-humano-computador.github.io/2020.1-UVaJudge/entrega_4/planejamento_teste_piloto/">aqui</a></p>

## 2. Objetivos da avaliação

<p align="justify"> &emsp;&emsp; Os objetivos serão expostos por meio de um conjunto de perguntas, segue abaixo as perguntas.</p>

1. Os percursos cognitivos identificados correspondem com as atividades executadas nas análises de tarefas?
2. O grid apresentado no Guia de Estilo apresenta melhorias eficientes?
3. Os erros diagnosticados nas avaliações individuais foram também identificados nos testes-piloto?
4. As atividades dos usuários foram devidamente identificadas?
5. Como os usuários realizam essas atividades segue o modelo trabalhado na análise CMN-GOMS?
6. Os objetivos das personas estão fiéis ao nosso perfil de usuário e aos dados coletados nas entrevitas e testes-piloto?
7. Os princípios gerais estão claros e bem definidos?
8. O erro encontrado na análise de tarefas da Maria lee Oliveira foi relatado durante o teste-piloto?
9. Os entrevistados conseguem se identificar com alguma história contada nos storyboards?

## 3. Metodologia

<p align="justify"> &emsp;&emsp; A nossa técnica adotada para a coleta dos dados será uma simbiose das técnicas existentes. A primeira delas será o percuso cognitivo, onde o avaliado irá simular que é um usuário, para isso, será usado as personas que foram criadas anteriomente. O segundo meio que vamos utilizar é a análise heurística, na qual, através de uma análise do UVa, iremos verificar se ele está dentro dos parâmetros esperados e estipulados das metas de usabilidades. Essa avaliação que vai ser útil pois é um método eficaz e rápido de encontrar os problemas de usabilidade mais básicos de um sistema. E o último vai ser pelas entrevistas e testes-pilotos feitos por vídeo-chamadas. Neles iremos verificar a qualidade dos protótipos, storyboards, grids e demais protótipos e ferramentas usadas no auxílio às análises criadas.</p>

<p align="justify"> &emsp;&emsp; Os entrevistados selecionados foram seletivamente escolhidos baseado em seu prévio contato com competições e disciplinas de programação. Dessa maneira, nossos dados estarão de acordo com o público alvo do UVa.</p>

## 4. Relato dos resultados

<p align="justify"> &emsp;&emsp; Os relatos vão ser colocados em um documento criado futuramente, nesse documento a ser gerado iremos colocar as respostas para as perguntas definidas na Seção 2. Os dados quantitativos obtidos serão colocados em forma de gráficos, enquantos os dados qualititativos serão expressos por meios de textos que vão demonstrar a qualidade e defeitos encontrados ao longo da avaliação. Assim, com essa avaliação poderemos definir se seguiremos para o nível 2 da seção de design, avaliação e desenvolvimento do ciclo Mayhew definido no processo de design.</p>

## 5. Versionamento

|Data|Versão|Descrição|Autor|
|:-:|:-:|:-:|:-:|
|27/09/2020|1.0|Adições nos tópicos 1, 2, 3 e 4|Sérgio Cipriano|
|27/09/2020|1.0|Adições nos tópicos 3 e 4|Washington Bispo|